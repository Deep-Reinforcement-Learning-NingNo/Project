{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3e0179",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "# FRA 503: Deep Reinforcement Learning\n",
    "\n",
    "**จัดทำโดย**\n",
    "1. อนวัช อนุสุเรนทร์ 65340500067\n",
    "2. ชัญญาภัค ทรัพย์สวัสดิ์กุล 65340500067"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840e2b7",
   "metadata": {},
   "source": [
    "## project overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976700f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7abf4e3",
   "metadata": {},
   "source": [
    "## Scopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5367e0",
   "metadata": {},
   "source": [
    "1. Use a custom Flappy Bird environment built with Gymnasium on Windows OS\n",
    "2. Limit to 2 types of observations only\n",
    "    - LIDAR-based >> 180 directional distance readings\n",
    "    - Game-state-based >> pipe positions, player position, velocity, and rotation\n",
    "3. Implement only 2 algorithms\n",
    "    - PPO as the baseline\n",
    "    - Dyna-PPO using Mamba2 for modeling environment dynamics and generating synthetic rollouts\n",
    "4. Do only single player features.\n",
    "5. Use only 1 pattern of seed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74ba59",
   "metadata": {},
   "source": [
    "## Problem formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241fc7a",
   "metadata": {},
   "source": [
    "## Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d34b7e",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e47285",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb0e33",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
